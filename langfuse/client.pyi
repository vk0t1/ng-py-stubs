# mypy: ignore-errors

import datetime as dt
import httpx
import pydantic
import typing
from _typeshed import Incomplete
from dataclasses import dataclass
from enum import Enum
from langfuse._task_manager.task_manager import TaskManager as TaskManager
from langfuse.api.client import AsyncFernLangfuse as AsyncFernLangfuse, FernLangfuse as FernLangfuse
from langfuse.api.resources.commons.types.dataset_run_with_items import DatasetRunWithItems as DatasetRunWithItems
from langfuse.api.resources.commons.types.observations_view import ObservationsView as ObservationsView
from langfuse.api.resources.commons.types.session import Session as Session
from langfuse.api.resources.commons.types.trace_with_details import TraceWithDetails as TraceWithDetails
from langfuse.api.resources.datasets.types.paginated_dataset_runs import PaginatedDatasetRuns as PaginatedDatasetRuns
from langfuse.api.resources.ingestion.types.create_event_body import CreateEventBody as CreateEventBody
from langfuse.api.resources.ingestion.types.create_generation_body import CreateGenerationBody as CreateGenerationBody
from langfuse.api.resources.ingestion.types.create_span_body import CreateSpanBody as CreateSpanBody
from langfuse.api.resources.ingestion.types.score_body import ScoreBody as ScoreBody
from langfuse.api.resources.ingestion.types.sdk_log_body import SdkLogBody as SdkLogBody
from langfuse.api.resources.ingestion.types.trace_body import TraceBody as TraceBody
from langfuse.api.resources.ingestion.types.update_generation_body import UpdateGenerationBody as UpdateGenerationBody
from langfuse.api.resources.ingestion.types.update_span_body import UpdateSpanBody as UpdateSpanBody
from langfuse.api.resources.media import GetMediaResponse as GetMediaResponse
from langfuse.api.resources.observations.types.observations_views import ObservationsViews as ObservationsViews
from langfuse.api.resources.prompts.types import CreatePromptRequest_Chat as CreatePromptRequest_Chat, CreatePromptRequest_Text as CreatePromptRequest_Text, Prompt_Chat as Prompt_Chat, Prompt_Text as Prompt_Text
from langfuse.api.resources.trace.types.traces import Traces as Traces
from langfuse.api.resources.utils.resources.pagination.types.meta_response import MetaResponse as MetaResponse
from langfuse.environment import get_common_release_envs as get_common_release_envs
from langfuse.logging import clean_logger as clean_logger
from langfuse.media import LangfuseMedia as LangfuseMedia
from langfuse.model import ChatMessageDict as ChatMessageDict, ChatPromptClient as ChatPromptClient, CreateDatasetItemRequest as CreateDatasetItemRequest, CreateDatasetRequest as CreateDatasetRequest, CreateDatasetRunItemRequest as CreateDatasetRunItemRequest, Dataset as Dataset, DatasetItem as DatasetItem, DatasetStatus as DatasetStatus, MapValue as MapValue, ModelUsage as ModelUsage, Observation as Observation, PromptClient as PromptClient, TextPromptClient as TextPromptClient, TraceWithFullDetails as TraceWithFullDetails
from langfuse.parse_error import handle_fern_exception as handle_fern_exception
from langfuse.prompt_cache import PromptCache as PromptCache
from langfuse.request import LangfuseClient as LangfuseClient
from langfuse.types import MaskFunction as MaskFunction, ScoreDataType as ScoreDataType, SpanLevel as SpanLevel
from typing import Any, Literal, Sequence, overload

ENVIRONMENT_PATTERN: str

@dataclass
class FetchTracesResponse:
    data: list[TraceWithDetails]
    meta: MetaResponse

@dataclass
class FetchTraceResponse:
    data: TraceWithFullDetails

@dataclass
class FetchObservationsResponse:
    data: list[ObservationsView]
    meta: MetaResponse

@dataclass
class FetchObservationResponse:
    data: Observation

@dataclass
class FetchMediaResponse:
    data: GetMediaResponse

@dataclass
class FetchSessionsResponse:
    data: list[Session]
    meta: MetaResponse

class Langfuse:
    log: Incomplete
    host: str
    project_id: str | None
    enabled: Incomplete
    base_url: Incomplete
    environment: Incomplete
    httpx_client: Incomplete
    api: Incomplete
    client: Incomplete
    async_api: Incomplete
    task_manager: Incomplete
    trace_id: Incomplete
    release: Incomplete
    prompt_cache: Incomplete
    def __init__(self, public_key: str | None = None, secret_key: str | None = None, host: str | None = None, release: str | None = None, debug: bool = False, threads: int | None = None, flush_at: int | None = None, flush_interval: float | None = None, max_retries: int | None = None, timeout: int | None = None, sdk_integration: str | None = 'default', httpx_client: httpx.Client | None = None, enabled: bool | None = True, sample_rate: float | None = None, mask: MaskFunction | None = None, environment: str | None = None) -> None: ...
    def get_trace_id(self) -> str: ...
    def get_trace_url(self) -> str: ...
    def get_dataset(self, name: str, *, fetch_items_page_size: int | None = 50) -> DatasetClient: ...
    def get_dataset_item(self, id: str) -> DatasetItemClient: ...
    def auth_check(self) -> bool: ...
    def get_dataset_runs(self, dataset_name: str, *, page: int | None = None, limit: int | None = None) -> PaginatedDatasetRuns: ...
    def get_dataset_run(self, dataset_name: str, dataset_run_name: str) -> DatasetRunWithItems: ...
    def create_dataset(self, name: str, description: str | None = None, metadata: Any | None = None) -> Dataset: ...
    def create_dataset_item(self, dataset_name: str, input: Any | None = None, expected_output: Any | None = None, metadata: Any | None = None, source_trace_id: str | None = None, source_observation_id: str | None = None, status: DatasetStatus | None = None, id: str | None = None) -> DatasetItem: ...
    def fetch_trace(self, id: str) -> FetchTraceResponse: ...
    def get_trace(self, id: str) -> TraceWithFullDetails: ...
    def fetch_traces(self, *, page: int | None = None, limit: int | None = None, user_id: str | None = None, name: str | None = None, session_id: str | None = None, from_timestamp: dt.datetime | None = None, to_timestamp: dt.datetime | None = None, order_by: str | None = None, tags: str | Sequence[str] | None = None) -> FetchTracesResponse: ...
    def get_traces(self, *, page: int | None = None, limit: int | None = None, user_id: str | None = None, name: str | None = None, session_id: str | None = None, from_timestamp: dt.datetime | None = None, to_timestamp: dt.datetime | None = None, order_by: str | None = None, tags: str | Sequence[str] | None = None) -> Traces: ...
    def fetch_observations(self, *, page: int | None = None, limit: int | None = None, name: str | None = None, user_id: str | None = None, trace_id: str | None = None, parent_observation_id: str | None = None, from_start_time: dt.datetime | None = None, to_start_time: dt.datetime | None = None, type: str | None = None) -> FetchObservationsResponse: ...
    def get_observations(self, *, page: int | None = None, limit: int | None = None, name: str | None = None, user_id: str | None = None, trace_id: str | None = None, parent_observation_id: str | None = None, from_start_time: dt.datetime | None = None, to_start_time: dt.datetime | None = None, type: str | None = None) -> ObservationsViews: ...
    def get_generations(self, *, page: int | None = None, limit: int | None = None, name: str | None = None, user_id: str | None = None, trace_id: str | None = None, from_start_time: dt.datetime | None = None, to_start_time: dt.datetime | None = None, parent_observation_id: str | None = None) -> ObservationsViews: ...
    def fetch_observation(self, id: str) -> FetchObservationResponse: ...
    def fetch_media(self, id: str) -> FetchMediaResponse: ...
    def resolve_media_references(self, *, obj: Any, resolve_with: Literal['base64_data_uri'], max_depth: int = 10, content_fetch_timeout_seconds: int = 10): ...
    def get_observation(self, id: str) -> Observation: ...
    def fetch_sessions(self, *, page: int | None = None, limit: int | None = None, from_timestamp: dt.datetime | None = None, to_timestamp: dt.datetime | None = None) -> FetchSessionsResponse: ...
    @overload
    def get_prompt(self, name: str, version: int | None = None, *, label: str | None = None, type: Literal['chat'], cache_ttl_seconds: int | None = None, fallback: list[ChatMessageDict] | None = None, max_retries: int | None = None, fetch_timeout_seconds: int | None = None) -> ChatPromptClient: ...
    @overload
    def get_prompt(self, name: str, version: int | None = None, *, label: str | None = None, type: Literal['text'] = 'text', cache_ttl_seconds: int | None = None, fallback: str | None = None, max_retries: int | None = None, fetch_timeout_seconds: int | None = None) -> TextPromptClient: ...
    @overload
    def create_prompt(self, *, name: str, prompt: list[ChatMessageDict], is_active: bool | None = None, labels: list[str] = [], tags: list[str] | None = None, type: Literal['chat'] | None, config: Any | None = None, commit_message: str | None = None) -> ChatPromptClient: ...
    @overload
    def create_prompt(self, *, name: str, prompt: str, is_active: bool | None = None, labels: list[str] = [], tags: list[str] | None = None, type: Literal['text'] | None = 'text', config: Any | None = None, commit_message: str | None = None) -> TextPromptClient: ...
    def update_prompt(self, *, name: str, version: int, new_labels: list[str] = []): ...
    def trace(self, *, id: str | None = None, name: str | None = None, user_id: str | None = None, session_id: str | None = None, version: str | None = None, input: typing.Any | None = None, output: typing.Any | None = None, metadata: typing.Any | None = None, tags: list[str] | None = None, timestamp: dt.datetime | None = None, public: bool | None = None, **kwargs) -> StatefulTraceClient: ...
    @overload
    def score(self, *, name: str, value: float, data_type: Literal['NUMERIC', 'BOOLEAN'] | None = None, trace_id: str | None = None, id: str | None = None, comment: str | None = None, observation_id: str | None = None, config_id: str | None = None, **kwargs) -> StatefulClient: ...
    @overload
    def score(self, *, name: str, value: str, data_type: Literal['CATEGORICAL'] | None = 'CATEGORICAL', trace_id: str | None = None, id: str | None = None, comment: str | None = None, observation_id: str | None = None, config_id: str | None = None, **kwargs) -> StatefulClient: ...
    def span(self, *, id: str | None = None, trace_id: str | None = None, parent_observation_id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, metadata: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, input: typing.Any | None = None, output: typing.Any | None = None, version: str | None = None, **kwargs) -> StatefulSpanClient: ...
    def event(self, *, id: str | None = None, trace_id: str | None = None, parent_observation_id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, metadata: typing.Any | None = None, input: typing.Any | None = None, output: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, **kwargs) -> StatefulSpanClient: ...
    def generation(self, *, id: str | None = None, trace_id: str | None = None, parent_observation_id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, completion_start_time: dt.datetime | None = None, metadata: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, model: str | None = None, model_parameters: dict[str, MapValue] | None = None, input: typing.Any | None = None, output: typing.Any | None = None, usage: pydantic.BaseModel | ModelUsage | None = None, usage_details: dict[str, int] | None = None, cost_details: dict[str, float] | None = None, prompt: PromptClient | None = None, **kwargs) -> StatefulGenerationClient: ...
    def join(self): ...
    def flush(self): ...
    def shutdown(self): ...

class StateType(Enum):
    OBSERVATION = 1
    TRACE = 0

class StatefulClient:
    log: Incomplete
    client: Incomplete
    trace_id: Incomplete
    id: Incomplete
    state_type: Incomplete
    task_manager: Incomplete
    environment: Incomplete
    def __init__(self, client: FernLangfuse, id: str, state_type: StateType, trace_id: str, task_manager: TaskManager, environment: str | None = None) -> None: ...
    def generation(self, *, id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, metadata: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, completion_start_time: dt.datetime | None = None, model: str | None = None, model_parameters: dict[str, MapValue] | None = None, input: typing.Any | None = None, output: typing.Any | None = None, usage: pydantic.BaseModel | ModelUsage | None = None, usage_details: dict[str, int] | None = None, cost_details: dict[str, float] | None = None, prompt: PromptClient | None = None, **kwargs) -> StatefulGenerationClient: ...
    def span(self, *, id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, metadata: typing.Any | None = None, input: typing.Any | None = None, output: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, **kwargs) -> StatefulSpanClient: ...
    @overload
    def score(self, *, id: str | None = None, name: str, value: float, data_type: Literal['NUMERIC', 'BOOLEAN'] | None = None, comment: str | None = None, config_id: str | None = None, **kwargs) -> StatefulClient: ...
    @overload
    def score(self, *, id: str | None = None, name: str, value: str, data_type: Literal['CATEGORICAL'] | None = 'CATEGORICAL', comment: str | None = None, config_id: str | None = None, **kwargs) -> StatefulClient: ...
    def event(self, *, id: str | None = None, name: str | None = None, start_time: dt.datetime | None = None, metadata: typing.Any | None = None, input: typing.Any | None = None, output: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, **kwargs) -> StatefulClient: ...
    def get_trace_url(self): ...

class StatefulGenerationClient(StatefulClient):
    log: Incomplete
    def __init__(self, client: FernLangfuse, id: str, state_type: StateType, trace_id: str, task_manager: TaskManager, environment: str | None = None) -> None: ...
    def update(self, *, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, completion_start_time: dt.datetime | None = None, metadata: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, model: str | None = None, model_parameters: dict[str, MapValue] | None = None, input: typing.Any | None = None, output: typing.Any | None = None, usage: pydantic.BaseModel | ModelUsage | None = None, usage_details: dict[str, int] | None = None, cost_details: dict[str, float] | None = None, prompt: PromptClient | None = None, **kwargs) -> StatefulGenerationClient: ...
    def end(self, *, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, completion_start_time: dt.datetime | None = None, metadata: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, model: str | None = None, model_parameters: dict[str, MapValue] | None = None, input: typing.Any | None = None, output: typing.Any | None = None, usage: pydantic.BaseModel | ModelUsage | None = None, usage_details: dict[str, int] | None = None, cost_details: dict[str, float] | None = None, prompt: PromptClient | None = None, **kwargs) -> StatefulGenerationClient: ...

class StatefulSpanClient(StatefulClient):
    log: Incomplete
    def __init__(self, client: FernLangfuse, id: str, state_type: StateType, trace_id: str, task_manager: TaskManager, environment: str | None = None) -> None: ...
    def update(self, *, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, metadata: typing.Any | None = None, input: typing.Any | None = None, output: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, **kwargs) -> StatefulSpanClient: ...
    def end(self, *, name: str | None = None, start_time: dt.datetime | None = None, end_time: dt.datetime | None = None, metadata: typing.Any | None = None, input: typing.Any | None = None, output: typing.Any | None = None, level: SpanLevel | None = None, status_message: str | None = None, version: str | None = None, **kwargs) -> StatefulSpanClient: ...
    def get_langchain_handler(self, update_parent: bool = False): ...

class StatefulTraceClient(StatefulClient):
    log: Incomplete
    task_manager: Incomplete
    def __init__(self, client: FernLangfuse, id: str, state_type: StateType, trace_id: str, task_manager: TaskManager, environment: str | None = None) -> None: ...
    def update(self, *, name: str | None = None, user_id: str | None = None, session_id: str | None = None, version: str | None = None, release: str | None = None, input: typing.Any | None = None, output: typing.Any | None = None, metadata: typing.Any | None = None, tags: list[str] | None = None, public: bool | None = None, **kwargs) -> StatefulTraceClient: ...
    def get_langchain_handler(self, update_parent: bool = False): ...
    def getNewHandler(self): ...

class DatasetItemClient:
    log: Incomplete
    id: str
    status: DatasetStatus
    input: typing.Any
    expected_output: typing.Any | None
    metadata: Any | None
    source_trace_id: str | None
    source_observation_id: str | None
    dataset_id: str
    dataset_name: str
    created_at: dt.datetime
    updated_at: dt.datetime
    langfuse: Langfuse
    def __init__(self, dataset_item: DatasetItem, langfuse: Langfuse) -> None: ...
    def flush(self, observation: StatefulClient, run_name: str): ...
    def link(self, trace_or_observation: StatefulClient | str | None, run_name: str, run_metadata: Any | None = None, run_description: str | None = None, trace_id: str | None = None, observation_id: str | None = None): ...
    def get_langchain_handler(self, *, run_name: str, run_description: str | None = None, run_metadata: Any | None = None): ...
    def observe(self, *, run_name: str, run_description: str | None = None, run_metadata: Any | None = None, trace_id: str | None = None): ...
    def observe_llama_index(self, *, run_name: str, run_description: str | None = None, run_metadata: Any | None = None, llama_index_integration_constructor_kwargs: dict[str, Any] | None = {}): ...
    def get_llama_index_handler(self, *, run_name: str, run_description: str | None = None, run_metadata: Any | None = None, llama_index_integration_constructor_kwargs: dict[str, Any] | None = {}): ...

class DatasetClient:
    id: str
    name: str
    description: str | None
    project_id: str
    dataset_name: str
    metadata: Any | None
    created_at: dt.datetime
    updated_at: dt.datetime
    items: list[DatasetItemClient]
    runs: list[str]
    def __init__(self, dataset: Dataset, items: list[DatasetItemClient]) -> None: ...
